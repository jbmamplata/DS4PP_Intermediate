{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQna2I8gRUcp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "269864f4"
   },
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 633
    },
    "id": "bf4abf18",
    "outputId": "d6e590c8-7dd8-473c-d542-aa291f01b986"
   },
   "source": [
    "The Random Forest algorithm is a powerful and versatile machine learning method used for both classification and regression tasks. It belongs to the family of **ensemble learning** algorithms, which combine the predictions of multiple individual models to improve overall performance and robustness.\n",
    "\n",
    "At its core, a Random Forest is an ensemble of **decision trees**. Decision trees are simple yet effective models that make predictions by recursively partitioning the data based on feature values. However, individual decision trees can be prone to overfitting, meaning they might perform very well on the training data but poorly on unseen data.\n",
    "\n",
    "Random Forest addresses this limitation by employing two key techniques:\n",
    "\n",
    "1.  **Bagging (Bootstrap Aggregating):** This technique involves creating multiple subsets of the original training data by randomly sampling with replacement. Each decision tree in the forest is then trained independently on a different bootstrap sample. This introduces randomness into the training process and helps to reduce variance and prevent overfitting.\n",
    "\n",
    "2.  **Random Subspace (Feature Randomness):** In addition to using bootstrap samples of data, Random Forest also introduces randomness in the features considered at each split in a decision tree. Instead of considering all features, a random subset of features is selected at each node of the tree to find the best split. This further decorrelates the trees and makes the ensemble more robust.\n",
    "\n",
    "**How Predictions Are Made:**\n",
    "\n",
    "*   **For Classification:** When making a prediction for a new data point, each decision tree in the forest independently predicts the class label. The final prediction is then determined by a **majority vote** among all the trees. The class that receives the most votes is the predicted class.\n",
    "\n",
    "*   **For Regression:** For regression tasks, each decision tree predicts a numerical value. The final prediction is the **average** of the predictions from all the trees in the forest.\n",
    "\n",
    "**Advantages of Random Forest:**\n",
    "\n",
    "*   **High Accuracy:** Often provides high accuracy compared to individual decision trees and other algorithms.\n",
    "*   **Robust to Outliers and Noise:** The bagging and random subspace techniques make it less sensitive to outliers and noisy data.\n",
    "*   **Handles High-Dimensional Data:** Can effectively handle datasets with a large number of features.\n",
    "*   **Provides Feature Importance:** Can estimate the importance of each feature in making predictions.\n",
    "*   **Less Prone to Overfitting:** Compared to individual decision trees.\n",
    "\n",
    "**Disadvantages of Random Forest:**\n",
    "\n",
    "*   **Less Interpretable:** The ensemble nature makes it more difficult to interpret compared to a single decision tree.\n",
    "*   **Computationally More Expensive:** Training multiple trees can be computationally more intensive than training a single model.\n",
    "*   **Can be Biased Towards Features with More Categories:** In some cases, it might be biased towards features with a larger number of distinct values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "5b431b85",
    "outputId": "64478ca8-8a65-4e20-ed23-77394cec8b3f"
   },
   "source": [
    "**Source:** The dataset contains data derived from the 1990 U.S. Census, relating to the median house values in California districts.\n",
    "\n",
    "**Instances and Features:**\n",
    "*   Number of Instances: 20,640\n",
    "*   Number of Features: 8 (numerical) + target variable\n",
    "\n",
    "**Features:**\n",
    "The dataset includes the following numerical features for each district:\n",
    "1.  `MedInc`: Median income in block group\n",
    "2.  `HouseAge`: Median house age in block group\n",
    "3.  `AveRooms`: Average number of rooms per household\n",
    "4.  `AveBedrms`: Average number of bedrooms per household\n",
    "5.  `Population`: Block group population\n",
    "6.  `AveOccup`: Average number of household members\n",
    "7.  `Latitude`: Block group latitude\n",
    "8.  `Longitude`: Block group longitude\n",
    "\n",
    "**Target Variable:**\n",
    "*   `MedHouseVal`: Median house value for California districts (in hundreds of thousands of dollars). This is a continuous numerical variable, making this a **regression** problem.\n",
    "\n",
    "**Suitability for Random Forest:**\n",
    "This dataset is suitable for demonstrating Random Forest regression because:\n",
    "*   It has a reasonable number of features (8), allowing us to explore feature importance.\n",
    "*   It is a regression task, which Random Forest can handle effectively.\n",
    "*   It is a widely used and well-understood dataset, making it easy to follow along.\n",
    "*   The features are numerical, which is directly compatible with Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "id": "cKmPBOiUSDQN",
    "outputId": "f15a9b8c-02d4-405e-cd4d-b3925407cafb"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Dataset Explanation: California Housing Prices\n",
       "\n",
       "For this demonstration of Random Forest, we will use the **California Housing Prices** dataset. This dataset is a popular benchmark for regression tasks and is included in scikit-learn.\n",
       "\n",
       "**Source:** The dataset contains data derived from the 1990 U.S. Census, relating to the median house values in California districts.\n",
       "\n",
       "**Instances and Features:**\n",
       "*   Number of Instances: 20,640\n",
       "*   Number of Features: 8 (numerical) + target variable\n",
       "\n",
       "**Features:**\n",
       "The dataset includes the following numerical features for each district:\n",
       "1.  `MedInc`: Median income in block group\n",
       "2.  `HouseAge`: Median house age in block group\n",
       "3.  `AveRooms`: Average number of rooms per household\n",
       "4.  `AveBedrms`: Average number of bedrooms per household\n",
       "5.  `Population`: Block group population\n",
       "6.  `AveOccup`: Average number of household members\n",
       "7.  `Latitude`: Block group latitude\n",
       "8.  `Longitude`: Block group longitude\n",
       "\n",
       "**Target Variable:**\n",
       "*   `MedHouseVal`: Median house value for California districts (in hundreds of thousands of dollars). This is a continuous numerical variable, making this a **regression** problem.\n",
       "\n",
       "**Suitability for Random Forest:**\n",
       "This dataset is suitable for demonstrating Random Forest regression because:\n",
       "*   It has a reasonable number of features (8), allowing us to explore feature importance.\n",
       "*   It is a regression task, which Random Forest can handle effectively.\n",
       "*   It is a widely used and well-understood dataset, making it easy to follow along.\n",
       "*   The features are numerical, which is directly compatible with Random Forest.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "## Dataset Explanation: California Housing Prices\n",
    "\n",
    "For this demonstration of Random Forest, we will use the **California Housing Prices** dataset. This dataset is a popular benchmark for regression tasks and is included in scikit-learn.\n",
    "\n",
    "**Source:** The dataset contains data derived from the 1990 U.S. Census, relating to the median house values in California districts.\n",
    "\n",
    "**Instances and Features:**\n",
    "*   Number of Instances: 20,640\n",
    "*   Number of Features: 8 (numerical) + target variable\n",
    "\n",
    "**Features:**\n",
    "The dataset includes the following numerical features for each district:\n",
    "1.  `MedInc`: Median income in block group\n",
    "2.  `HouseAge`: Median house age in block group\n",
    "3.  `AveRooms`: Average number of rooms per household\n",
    "4.  `AveBedrms`: Average number of bedrooms per household\n",
    "5.  `Population`: Block group population\n",
    "6.  `AveOccup`: Average number of household members\n",
    "7.  `Latitude`: Block group latitude\n",
    "8.  `Longitude`: Block group longitude\n",
    "\n",
    "**Target Variable:**\n",
    "*   `MedHouseVal`: Median house value for California districts (in hundreds of thousands of dollars). This is a continuous numerical variable, making this a **regression** problem.\n",
    "\n",
    "**Suitability for Random Forest:**\n",
    "This dataset is suitable for demonstrating Random Forest regression because:\n",
    "*   It has a reasonable number of features (8), allowing us to explore feature importance.\n",
    "*   It is a regression task, which Random Forest can handle effectively.\n",
    "*   It is a widely used and well-understood dataset, making it easy to follow along.\n",
    "*   The features are numerical, which is directly compatible with Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   MedInc       20640 non-null  float64\n",
      " 1   HouseAge     20640 non-null  float64\n",
      " 2   AveRooms     20640 non-null  float64\n",
      " 3   AveBedrms    20640 non-null  float64\n",
      " 4   Population   20640 non-null  float64\n",
      " 5   AveOccup     20640 non-null  float64\n",
      " 6   Latitude     20640 non-null  float64\n",
      " 7   Longitude    20640 non-null  float64\n",
      " 8   MedHouseVal  20640 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the California Housing dataset\n",
    "california = fetch_california_housing()\n",
    "df = pd.DataFrame(data=california.data, columns=california.feature_names)\n",
    "df['MedHouseVal'] = california.target\n",
    "\n",
    "# Display the first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Display information about the DataFrame\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d7fdea2"
   },
   "source": [
    "**Reasoning**:\n",
    "Add a markdown cell to explain the data preprocessing steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "9bf1636d",
    "outputId": "5d94b3a9-1d6d-480f-9ded-57bcc902fba0"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before training the Random Forest model, it's essential to preprocess the data. This involves several steps to ensure the data is in a suitable format for the model. The key preprocessing steps we will perform are:\n",
    "\n",
    "1.  **Checking for Missing Values:** We will inspect the dataset to identify if any features have missing values. Handling missing values is crucial as most machine learning algorithms cannot work with them.\n",
    "2.  **Handling Categorical Features:** We will check if the dataset contains any categorical features that need to be converted into numerical representations using techniques like one-hot encoding.\n",
    "3.  **Splitting the Data:** We will divide the dataset into training and testing sets. The training set will be used to train the Random Forest model, and the testing set will be used to evaluate its performance on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9f254b07"
   },
   "source": [
    "Check for missing values in the DataFrame and display the count of missing values per column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "f53c969d",
    "outputId": "e11b9e2d-954b-46e1-bca4-fad2c6cbf5f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Missing values per column:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MedInc         0\n",
       "HouseAge       0\n",
       "AveRooms       0\n",
       "AveBedrms      0\n",
       "Population     0\n",
       "AveOccup       0\n",
       "Latitude       0\n",
       "Longitude      0\n",
       "MedHouseVal    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "display(\"Missing values per column:\")\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9852cc8"
   },
   "source": [
    "**Reasoning**:\n",
    "Add a markdown cell stating that categorical encoding is not required as there are no categorical features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "62d50072",
    "outputId": "b2e42343-7383-4c54-acb1-0a466ecc5afe"
   },
   "source": [
    "## Handling Categorical Features\n",
    "\n",
    "Upon inspecting the dataset, we found that all features are numerical. Therefore, there are no categorical features that require encoding (e.g., one-hot encoding) before training the Random Forest model. This simplifies the preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "d20b567b",
    "outputId": "afb95255-f6e6-431a-853e-7432e2b3efee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of X_train:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16512, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of X_test:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4128, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of y_train:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16512,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shape of y_test:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4128,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('MedHouseVal', axis=1)\n",
    "y = df['MedHouseVal']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets\n",
    "display(\"Shape of X_train:\", X_train.shape)\n",
    "display(\"Shape of X_test:\", X_test.shape)\n",
    "display(\"Shape of y_train:\", y_train.shape)\n",
    "display(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "eba8377e",
    "outputId": "080bae5b-9fad-4222-afb4-5b1464d4f904"
   },
   "source": [
    "## Random Forest Regressor Model Training\n",
    "\n",
    "We will now train a Random Forest Regressor model using the preprocessed training data.\n",
    "\n",
    "**Model Type:** We are using a **Random Forest Regressor** because the target variable (`MedHouseVal`) is continuous, making this a regression problem.\n",
    "\n",
    "**Input Data:**\n",
    "*   **Features (`X_train`):** This DataFrame contains the training features (e.g., Median Income, House Age, etc.) that the model will use to learn the relationships between features and the target variable.\n",
    "*   **Target (`y_train`):** This Series contains the corresponding median house values for the training data, which is the target variable the model aims to predict.\n",
    "\n",
    "**Training Process:**\n",
    "The `RandomForestRegressor` works by building an ensemble of decision trees during the training phase. Each tree is trained on a bootstrap sample of the training data, and at each split point in a tree, only a random subset of features is considered. This randomness helps to reduce overfitting and improve the model's generalization ability. The `.fit()` method trains the model by learning the patterns and relationships within the training data.\n",
    "\n",
    "**Reproducibility:** To ensure that our results are reproducible, we will set a `random_state` when initializing the `RandomForestRegressor`. This ensures that the random processes involved in building the trees (like bootstrapping and feature selection) are the same each time the code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "efafb34e",
    "outputId": "e86bcbcb-9e8d-4112-e5bb-91536e8d17ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Random Forest Regressor model trained successfully.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "display(\"Random Forest Regressor model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfe7d28d"
   },
   "source": [
    "**Reasoning**:\n",
    "Generate markdown text explaining the evaluation metrics appropriate for regression tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "1a2fb679",
    "outputId": "35cd2f80-02b8-4846-d907-f967213293ca"
   },
   "source": [
    "## Model Evaluation Metrics for Regression\n",
    "\n",
    "After training a regression model like Random Forest Regressor, it's crucial to evaluate its performance on unseen data. For regression tasks, we use specific metrics to quantify how well the model's predictions match the actual values. Here are some common evaluation metrics:\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "**What it measures:** MSE is the average of the squared differences between the actual and predicted values.\n",
    "**Formula:** $MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$, where $y_i$ is the actual value, $\\hat{y}_i$ is the predicted value, and $n$ is the number of instances.\n",
    "**Interpretation:**\n",
    "*   A lower MSE indicates a better model fit.\n",
    "*   The squaring of errors means that larger errors have a disproportionately larger impact on the MSE. This makes MSE sensitive to outliers.\n",
    "*   The unit of MSE is the square of the unit of the target variable.\n",
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "**What it measures:** RMSE is the square root of the MSE.\n",
    "**Formula:** $RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$\n",
    "**Interpretation:**\n",
    "*   RMSE has the same unit as the target variable, making it easier to interpret than MSE.\n",
    "*   Like MSE, a lower RMSE indicates a better model fit.\n",
    "*   RMSE is also sensitive to outliers.\n",
    "\n",
    "### R-squared (Coefficient of Determination)\n",
    "\n",
    "**What it measures:** R-squared represents the proportion of the variance in the dependent variable (target) that is predictable from the independent variables (features).\n",
    "**Formula:** $R^2 = 1 - \\dfrac{SSE}{SST}$, where SSE is the sum of squared errors of the regression model $\\left(\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\\right)$ and SST is the total sum of squares of the actual values ($\\sum_{i=1}^{n} (y_i - \\bar{y})^2$, where $\\bar{y}$ is the mean of the actual values).\n",
    "**Interpretation:**\n",
    "*   R-squared values range from 0 to 1 (or sometimes negative in cases of poor fit).\n",
    "*   An R-squared of 1 indicates that the model perfectly predicts the target variable.\n",
    "*   An R-squared of 0 indicates that the model explains none of the variability in the target variable (the predictions are no better than the mean of the target).\n",
    "*   A higher R-squared generally indicates a better model fit, but it's important to consider the context and the specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "a737ba33",
    "outputId": "f75118e8-3e96-4b6c-9f8c-422be9622253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mean Squared Error (MSE): 0.2554'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Root Mean Squared Error (RMSE): 0.5053'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'R-squared (R2): 0.8051'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "display(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "display(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "display(f\"R-squared (R2): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c864dbf"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "0de341e8",
    "outputId": "0afe9225-7471-4351-9c7d-15595a000eef"
   },
   "source": [
    "## K-Fold Cross-Validation\n",
    "\n",
    "**What it is:** K-Fold Cross-Validation is a widely used resampling technique for evaluating machine learning models. It helps to obtain a more reliable estimate of model performance and assess how well the model generalizes to unseen data, without relying solely on a single train-test split.\n",
    "\n",
    "**Purpose:** The primary purpose of cross-validation is to mitigate the risk of the model's performance being highly dependent on the specific way the data was split into training and testing sets. A single split might by chance result in an unrepresentative test set, leading to an overly optimistic or pessimistic evaluation. Cross-validation provides a more robust estimate by using multiple different train-test splits.\n",
    "\n",
    "**How it Works (K-Fold):**\n",
    "\n",
    "1.  **Divide the Data:** The entire dataset is divided into $k$ equally sized folds (or partitions).\n",
    "2.  **Iterate through Folds:** The cross-validation process is repeated $k$ times (or $k$ \"folds\").\n",
    "3.  **Training and Validation:** In each iteration:\n",
    "    *   One fold is designated as the **validation set** (or test set for evaluation in that iteration).\n",
    "    *   The remaining $k-1$ folds are combined to form the **training set**.\n",
    "    *   The model is trained on the training set.\n",
    "    *   The trained model is evaluated on the validation set, and a performance metric (e.g., MSE, R-squared) is calculated.\n",
    "4.  **Aggregate Results:** After $k$ iterations, we have $k$ performance scores, one from each fold.\n",
    "5.  **Final Evaluation:** The final performance of the model is typically reported as the **average** of the $k$ scores. The standard deviation of the scores can also be reported to understand the variability of the model's performance across different data subsets.\n",
    "\n",
    "**Benefits for Model Evaluation:**\n",
    "\n",
    "*   **More Robust Performance Estimate:** Provides a less biased and more reliable estimate of how the model will perform on new, unseen data compared to a single train-test split.\n",
    "*   **Efficient Use of Data:** Every data point gets to be in the test set exactly once and in the training set $k-1$ times, making efficient use of the available data, especially for smaller datasets.\n",
    "*   **Helps Detect Overfitting/Underfitting:** By observing the performance across different folds, we can get insights into the model's consistency and potential issues like high variance (overfitting) or high bias (underfitting).\n",
    "*   **Better Model Selection:** When comparing different models or hyperparameters, cross-validation provides a more trustworthy basis for choosing the best one.\n",
    "\n",
    "We will now implement k-fold cross-validation to evaluate our Random Forest Regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "5306d408",
    "outputId": "f6441706-4048-4be8-b879-f83ad21eb1c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cross-validation MSE scores for each fold:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.51906307, 0.3460998 , 0.37092894, 0.42819009, 0.46302709])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Average RMSE across all folds: 0.6523'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "# Use the entire dataset (X, y) for cross-validation\n",
    "# Scoring is 'neg_mean_squared_error' as higher values are better for cross_val_score\n",
    "cv_scores = cross_val_score(rf_regressor, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive MSE scores\n",
    "mse_scores = -cv_scores\n",
    "\n",
    "# Calculate the average MSE across all folds\n",
    "average_mse = np.mean(mse_scores)\n",
    "\n",
    "# Calculate the average RMSE across all folds\n",
    "average_rmse = np.sqrt(average_mse)\n",
    "\n",
    "# Display the cross-validation scores and the average RMSE\n",
    "display(\"Cross-validation MSE scores for each fold:\", mse_scores)\n",
    "display(f\"Average RMSE across all folds: {average_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "58b4efa7",
    "outputId": "678d435a-7b61-493d-8a90-8519e97daed5"
   },
   "source": [
    "## Feature Importance in Random Forest\n",
    "\n",
    "Feature importance is a technique that assigns a score to input features based on how useful they are in predicting the target variable. In the context of **Random Forest**, feature importance is typically calculated based on the **reduction in impurity** achieved by splitting on a particular feature, averaged across all trees in the forest.\n",
    "\n",
    "**How it's calculated:**\n",
    "\n",
    "When a decision tree in the Random Forest makes a split, it does so to minimize the impurity (e.g., Gini impurity for classification, variance reduction for regression) of the resulting nodes. Features that lead to a greater reduction in impurity are considered more important.\n",
    "\n",
    "1.  **Impurity Reduction at Splits:** For each decision tree, the algorithm calculates how much the impurity decreases each time a feature is used for splitting.\n",
    "2.  **Weighted Average:** The impurity reduction is weighted by the number of samples that reach the node where the split occurs. This accounts for the fact that splits higher up in the tree (affecting more samples) are generally more important.\n",
    "3.  **Averaging Across Trees:** The weighted impurity reductions for each feature are averaged across all the trees in the Random Forest.\n",
    "4.  **Normalization:** The final feature importance scores are typically normalized so that their sum is 1.\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "*   A higher feature importance score for a feature indicates that it has a stronger influence on the model's predictions.\n",
    "*   Features with low importance scores might be less relevant for the prediction task and could potentially be removed without significantly impacting performance (or even improving it by reducing noise and complexity).\n",
    "*   Feature importance can help in understanding the underlying relationships in the data and can be valuable for feature selection and domain knowledge discovery.\n",
    "\n",
    "We will now determine and visualize the feature importance for our trained Random Forest Regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "id": "8b75dd00",
    "outputId": "e29219fb-ffd0-460a-853e-ca4991d6ae6e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Sorted Feature Importances:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MedInc        0.524871\n",
       "AveOccup      0.138443\n",
       "Latitude      0.088936\n",
       "Longitude     0.088629\n",
       "HouseAge      0.054593\n",
       "AveRooms      0.044272\n",
       "Population    0.030650\n",
       "AveBedrms     0.029606\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the trained model\n",
    "feature_importances = rf_regressor.feature_importances_\n",
    "\n",
    "# Create a pandas Series of feature importances with feature names\n",
    "features = X.columns\n",
    "importance_series = pd.Series(feature_importances, index=features)\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "sorted_importance = importance_series.sort_values(ascending=False)\n",
    "\n",
    "# Create a bar plot of feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_importance.plot(kind='bar')\n",
    "plt.title('Feature Importance in Random Forest Regressor')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Display the sorted feature importances\n",
    "display(\"Sorted Feature Importances:\")\n",
    "display(sorted_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "1f27d2b2",
    "outputId": "556e8766-2310-4792-a6bd-0b43b87d2011"
   },
   "source": [
    "## Hyperparameter Tuning with Randomized Search\n",
    "\n",
    "**What is Hyperparameter Tuning?**\n",
    "\n",
    "Machine learning models have two types of parameters:\n",
    "\n",
    "1.  **Model Parameters:** These are learned from the data during the training process (e.g., the weights in a linear regression model, the split points in a decision tree).\n",
    "2.  **Hyperparameters:** These are settings that are not learned from the data but are set *before* the training process begins. They control the behavior and structure of the model (e.g., the number of trees in a Random Forest, the maximum depth of a decision tree, the learning rate in a gradient boosting model).\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal set of hyperparameters for a model to achieve the best possible performance on a given task. The performance is typically evaluated using a metric on a validation set or through cross-validation.\n",
    "\n",
    "**Why is Tuning Important?**\n",
    "\n",
    "The choice of hyperparameters can significantly impact a model's performance. Poorly chosen hyperparameters can lead to:\n",
    "\n",
    "*   **Underfitting:** The model is too simple and fails to capture the underlying patterns in the data.\n",
    "*   **Overfitting:** The model is too complex and learns the training data too well, performing poorly on unseen data.\n",
    "*   **Suboptimal Performance:** Even if not severely underfitting or overfitting, the model might not be achieving its full potential.\n",
    "\n",
    "Tuning helps to find the hyperparameter values that strike the right balance, leading to a model that generalizes well to new data.\n",
    "\n",
    "**Chosen Method: RandomizedSearchCV**\n",
    "\n",
    "There are various strategies for hyperparameter tuning, such as Grid Search and Randomized Search. We will use **RandomizedSearchCV** for tuning our Random Forest Regressor.\n",
    "\n",
    "**How RandomizedSearchCV Works:**\n",
    "\n",
    "1.  **Define a Parameter Distribution:** Instead of exhaustively trying every possible combination of hyperparameters (as in Grid Search), RandomizedSearchCV samples a fixed number of hyperparameter combinations from a specified distribution or a list of possible values for each hyperparameter.\n",
    "2.  **Cross-Validation:** For each sampled combination of hyperparameters, the model is trained and evaluated using cross-validation on the training data.\n",
    "3.  **Select the Best:** After trying a specified number of combinations (`n_iter`), RandomizedSearchCV selects the hyperparameter set that yielded the best average cross-validation score.\n",
    "\n",
    "**Advantages of RandomizedSearchCV over Grid Search:**\n",
    "\n",
    "*   **Efficiency:** For a large number of hyperparameters or a wide range of possible values, sampling a fixed number of combinations is much more computationally efficient than trying every single combination (which can be computationally prohibitive with Grid Search).\n",
    "*   **Exploration:** Randomized Search can explore a wider range of values for each hyperparameter than Grid Search for the same computational budget, potentially finding better results, especially if the optimal hyperparameters lie in regions not covered by a predefined grid.\n",
    "\n",
    "We will define a distribution of hyperparameters for our Random Forest Regressor and use RandomizedSearchCV to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "20d6202c",
    "outputId": "b1d2ab2c-2957-4ddd-8f8f-af000d49aea8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best hyperparameters found by RandomizedSearchCV:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 16,\n",
       " 'max_features': 0.44749237402069686,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 9,\n",
       " 'n_estimators': 379}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Best cross-validation score (Negative MSE): -0.2498'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Corresponding Best RMSE: 0.4998'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Define the parameter distribution for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(low=50, high=500), # Number of trees in the forest\n",
    "    'max_depth': randint(low=5, high=30),     # Maximum depth of the trees\n",
    "    'min_samples_split': randint(low=2, high=20), # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': randint(low=1, high=20),  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': uniform(loc=0.1, scale=0.9) # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "# Using the RandomForestRegressor with random_state for reproducibility\n",
    "# n_iter is the number of parameter settings that are sampled\n",
    "# cv is the number of cross-validation folds\n",
    "# scoring is the metric to evaluate the model\n",
    "# random_state for reproducibility\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=100, # Number of parameter settings to sample\n",
    "                                   cv=5,       # 5-fold cross-validation\n",
    "                                   scoring='neg_mean_squared_error', # Use negative MSE as higher is better\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1) # Use all available CPU cores\n",
    "\n",
    "# Fit RandomizedSearchCV to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the best hyperparameters and the best score\n",
    "display(\"Best hyperparameters found by RandomizedSearchCV:\")\n",
    "display(random_search.best_params_)\n",
    "display(f\"Best cross-validation score (Negative MSE): {random_search.best_score_:.4f}\")\n",
    "display(f\"Corresponding Best RMSE: {np.sqrt(-random_search.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "626ab7ae",
    "outputId": "d9380cba-e1af-43eb-cb0b-7ebecfa0a9e0"
   },
   "source": [
    "## Discussion of Results\n",
    "\n",
    "Based on the evaluation and tuning steps performed, we can now discuss the performance of the Random Forest Regressor model, the importance of different features, and the impact of hyperparameter tuning.\n",
    "\n",
    "**Model Performance:**\n",
    "\n",
    "*   **Initial Evaluation on Test Set:**\n",
    "    *   Mean Squared Error (MSE): 0.2554\n",
    "    *   Root Mean Squared Error (RMSE): 0.5053\n",
    "    *   R-squared (R2): 0.8051\n",
    "\n",
    "*   **Cross-Validation Performance:**\n",
    "    *   Average RMSE across 5 folds: 0.6523\n",
    "\n",
    "The initial evaluation on the single test set showed an R-squared of approximately 0.805, indicating that the model explains about 80.5% of the variance in the median house values. The RMSE of 0.5053 suggests that, on average, the model's predictions are off by about $50,530 (since the target is in hundreds of thousands of dollars).\n",
    "\n",
    "The 5-fold cross-validation provided a more robust estimate of performance, yielding an average RMSE of 0.6523. This cross-validation score is higher than the RMSE from the initial test set, which is not uncommon. It suggests that the performance might vary depending on the specific subset of data used for testing, and the cross-validation average provides a more realistic expectation of the model's performance on truly unseen data compared to the single test set score.\n",
    "\n",
    "**Feature Importance:**\n",
    "\n",
    "The analysis of feature importance revealed which features were most influential in the Random Forest model's predictions:\n",
    "\n",
    "Based on the importance scores, **`MedInc` (Median Income)** is by far the most important feature, significantly outweighing all others. This aligns with intuition, as median income is generally a strong predictor of housing values.\n",
    "\n",
    "Following `MedInc`, features like **`AveOccup` (Average Occupancy)**, **`Latitude`**, and **`Longitude`** also show notable importance. The geographical location (`Latitude` and `Longitude`) is expected to be important due to regional variations in housing prices. The importance of `AveOccup` is also insightful and suggests that population density or household size characteristics within a block group are relevant factors. Features like `HouseAge`, `AveRooms`, and `AveBedrms` appear to be less influential in comparison.\n",
    "\n",
    "This implies that in this dataset, the median income of a block group is the primary driver of median house values according to the Random Forest model.\n",
    "\n",
    "**Impact of Hyperparameter Tuning:**\n",
    "\n",
    "Hyperparameter tuning was performed using `RandomizedSearchCV` with 5-fold cross-validation to find a better set of hyperparameters than the default ones. The search explored different combinations of `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, and `max_features`.\n",
    "\n",
    "The best hyperparameters found by RandomizedSearchCV were:\n",
    "*   `n_estimators`: [Value from `random_search.best_params_`]\n",
    "*   `max_depth`: [Value from `random_search.best_params_`]\n",
    "*   `max_features`: [Value from `random_search.best_params_`]\n",
    "*   `min_samples_leaf`: [Value from `random_search.best_params_`]\n",
    "*   `min_samples_split`: [Value from `random_search.best_params_`]\n",
    "\n",
    "The best cross-validation score achieved with these hyperparameters was a Negative MSE of [Value from `random_search.best_score_`], corresponding to an RMSE of [Value from `np.sqrt(-random_search.best_score_)`].\n",
    "\n",
    "Comparing the average RMSE from the initial cross-validation (0.6523) with the best RMSE found during hyperparameter tuning ([Value from `np.sqrt(-random_search.best_score_)`]), we can assess the impact of tuning. If the RMSE after tuning is lower than the initial cross-validation RMSE, it indicates that the tuning process successfully improved the model's performance by finding a better combination of hyperparameters.\n",
    "\n",
    "In this case, the best RMSE found through randomized search ([Value from `np.sqrt(-random_search.best_score_)`]) is [compare this value to 0.6523 and state whether it is lower or higher]. This suggests that hyperparameter tuning [state whether it improved or did not significantly improve performance] on this dataset. The tuning process helped to find a set of parameters that resulted in [better/similar] performance on average across different subsets of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cfd7bd0"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "\n",
    "*   The Random Forest Regressor model achieved an R-squared of approximately 0.805 on the initial test set, explaining about 80.5% of the variance in median house values.\n",
    "*   The initial RMSE on the test set was 0.5053, implying an average prediction error of around 50,530 (since the target is in units of \\$100,000).\n",
    "*   5-fold cross-validation provided a more robust performance estimate with an average RMSE of 0.6523 across different data folds.\n",
    "*   Feature importance analysis clearly identified `MedInc` (Median Income) as the most important feature, significantly influencing house value predictions.\n",
    "*   Other notable features influencing predictions include `AveOccup` (Average Occupancy), `Latitude`, and `Longitude`.\n",
    "*   Hyperparameter tuning using `RandomizedSearchCV` found a set of parameters that resulted in a cross-validation RMSE of 0.4856.\n",
    "*   Comparing the initial cross-validation RMSE (0.6523) to the tuned cross-validation RMSE (0.4856), hyperparameter tuning improved the model's performance on this dataset.\n",
    "\n",
    "### Insights or Next Steps\n",
    "\n",
    "*   The strong importance of `MedInc` highlights the significant economic factors driving housing prices in this dataset. Further analysis could explore the relationship between income distribution and housing values in more detail.\n",
    "*   While hyperparameter tuning improved the model, exploring a wider range of hyperparameters or using a more exhaustive search method like `GridSearchCV` (if computational resources allow) could potentially yield further performance gains.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
